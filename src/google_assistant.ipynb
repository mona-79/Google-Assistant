{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNeoi8sP0vsdpUWPs+zRgP/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mona-79/Google-Assistant/blob/main/src/google_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "RQKhmpnzi2mA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gTTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KABGL20oj9-V",
        "outputId": "5b1bf231-d52d-4e7f-8286-ab300fd3f85a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "from gtts import gTTS\n",
        "\n",
        "from google.colab import userdata\n",
        "userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "genai.configure(api_key= 'GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "xAiLBSu8kZ8V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "jo7YILOCke8j"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ask_question(name):\n",
        "  ques = 'Hello ' + name + ', how may I assist you ?'\n",
        "  ques = input(ques)\n",
        "  return ques"
      ],
      "metadata": {
        "id": "O_VuPxYpAMqd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_question(\"Mona\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "WMCd4LwzAdgC",
        "outputId": "87106ef8-a220-4c33-b8f3-908566013ba9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello Mona, how may I assist you ?ok\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ok'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_questions(ques):\n",
        "  goahead_with_websearch = False\n",
        "  device_lst = ['alarm','reminder','call', 'message', 'remind']\n",
        "  prsnl_lst = ['who are you','who created you']\n",
        "\n",
        "  device = False\n",
        "  for i in device_lst:\n",
        "    if i in ques:\n",
        "      device = True\n",
        "  if device:\n",
        "    print(\"We can't Handle that kind of Support at the Moment\")\n",
        "\n",
        "  personal = False\n",
        "  for i in prsnl_lst:\n",
        "    if i in ques.lower():\n",
        "      personal = True\n",
        "  if personal:\n",
        "    print(\"I am  your Google Asisstant, and I am created by Mona\")\n",
        "\n",
        "  if device:\n",
        "    goahead_with_websearch = False\n",
        "  elif personal:\n",
        "    goahead_with_websearch = False\n",
        "  else:\n",
        "    goahead_with_websearch = True\n",
        "    return goahead_with_websearch"
      ],
      "metadata": {
        "id": "8BjNOkCjAhYl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classify_questions(\"remind me that i have to go to a meeting.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K_6AtTPNIzA",
        "outputId": "ea33596c-77a2-44fb-f30f-9179acd4a9f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We can't Handle that kind of Support at the Moment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start searching with google gemini"
      ],
      "metadata": {
        "id": "OmdlyNjCNMXY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_gemini(ques):\n",
        "  modified_prompt = 'Hey give me answer to this question: '+ ques + ' in maximum of 50 words'\n",
        "  response = model.generate_content(modified_prompt)\n",
        "  to_markdown(response.text)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "Yk3Os0_QNzDr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speak(answer):\n",
        "  tts = gTTS(answer)\n",
        "  tts.save('audio.mp3')\n",
        "  display(Audio('audio.mp3', autoplay=True))"
      ],
      "metadata": {
        "id": "gOQK0jseOrCP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "have_more_ques = 'y'\n",
        "name = ''\n",
        "\n",
        "while have_more_ques == 'y':\n",
        "  if name == '':\n",
        "    name = input(\"What is your name? - \")\n",
        "\n",
        "  q = ask_question(name)\n",
        "\n",
        "  go_ahead = classify_questions(q)\n",
        "  answer = ''\n",
        "\n",
        "  if go_ahead == True:\n",
        "    answer = ask_gemini(q)\n",
        "    speak(answer)\n",
        "    print(answer)\n",
        "\n",
        "  have_more_ques = input(\"Anything else \" + name + \" ?\")\n"
      ],
      "metadata": {
        "id": "hl_n3sbJOumn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eD3Lb6CBPIlE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}